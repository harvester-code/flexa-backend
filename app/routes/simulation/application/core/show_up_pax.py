"""
ìŠ¹ê° ìŠ¤ì¼€ì¤„ ìƒì„± í•µì‹¬ ë¡œì§ (Passenger Schedule Generation Core Logic)

ì´ ëª¨ë“ˆì€ ë³µì¡í•œ ìŠ¹ê° ìŠ¤ì¼€ì¤„ ìƒì„± ë¡œì§ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤:
- í•­ê³µí¸ ë°ì´í„°ë¥¼ ê°œë³„ ìŠ¹ê°ìœ¼ë¡œ í™•ì¥
- ì¸êµ¬í†µê³„ ì •ë³´ í• ë‹¹ (êµ­ì , í”„ë¡œí•„ ë“±)
- ìŠ¹ê°ë³„ ê³µí•­ ë„ì°©ì‹œê°„ ìƒì„±
- S3ì— ìŠ¹ê° ë°ì´í„° ì €ì¥
"""

import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional

import numpy as np
import pandas as pd
from fastapi import HTTPException, status
from loguru import logger

import awswrangler as wr
from packages.secrets import get_secret
from packages.storages import boto3_session, check_s3_object_exists


class PassengerGenerator:
    """ìŠ¹ê° ìŠ¤ì¼€ì¤„ ìƒì„± í•µì‹¬ ë¡œì§"""

    async def generate(self, scenario_id: str, config: dict) -> Dict:
        """ìŠ¹ê° ìŠ¤ì¼€ì¤„ ìƒì„± ë©”ì¸ ë©”ì„œë“œ"""
        try:
            # 1. ì„¤ì •ê°’ ì¶”ì¶œ (ê¸°ë³¸ê°’ ì—†ì´ ê°•ì œ ì…ë ¥)
            settings = config.get("settings", {})

            # í•„ìˆ˜ ì…ë ¥ê°’ ê²€ì¦
            if "load_factor" not in settings:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="load_factor is required in settings",
                )
            if "target_date" not in settings:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="target_date is required in settings",
                )
            if "departure_airport" not in settings:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="departure_airport is required in settings",
                )

            load_factor = settings["load_factor"]
            target_date = settings["target_date"]
            departure_airport = settings["departure_airport"]

            # 2. S3ì—ì„œ flight-schedule ë°ì´í„° ë¡œë“œ (í•„í„°ë§ ì„¤ì • ì „ë‹¬)
            flight_data = await self._load_flight_data_from_s3(
                scenario_id, target_date, departure_airport
            )
            if not flight_data:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail="Flight schedule data not found. Please load flight schedule first.",
                )

            # 3. ìŠ¹ê° ë°ì´í„° ìƒì„±
            flight_df = pd.DataFrame(flight_data)

            # 4. ìŠ¹ê° í™•ì¥
            pax_df = await self._expand_flights_to_passengers(flight_df, load_factor)

            # 5. ì¸êµ¬í†µê³„ í• ë‹¹
            pax_df = await self._assign_passenger_demographics(pax_df, config)

            # 6. ë„ì°©ì‹œê°„ ìƒì„±
            pax_df = await self._assign_show_up_times(pax_df, config)

            # 7. S3ì— ì €ì¥
            await self._save_passenger_data_to_s3(pax_df, scenario_id)

            # 8. ì‘ë‹µ ë°ì´í„° ìƒì„± ë° ë°˜í™˜
            return await self._build_passenger_schedule_response(pax_df, config)

        except HTTPException:
            # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
            raise
        except Exception as e:
            logger.error(f"Passenger schedule generation failed: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"Failed to generate passenger schedule: {str(e)}",
            )

    # =====================================
    # Private Helper Methods
    # =====================================

    async def _load_flight_data_from_s3(
        self, scenario_id: str, target_date: str, departure_airport: str
    ) -> Optional[List[Dict]]:
        """S3ì—ì„œ í•­ê³µí¸ ë°ì´í„° ë¡œë“œ"""
        try:
            object_exists = check_s3_object_exists(
                bucket_name=get_secret("AWS_S3_BUCKET_NAME"),
                object_key=f"{scenario_id}/flight-schedule.parquet",
            )

            if not object_exists:
                return None

            df = wr.s3.read_parquet(
                path=f"s3://{get_secret('AWS_S3_BUCKET_NAME')}/{scenario_id}/flight-schedule.parquet",
                boto3_session=boto3_session,
            )

            logger.info(f"ì›ë³¸ ë°ì´í„°: {len(df):,}ê°œ")

            # 1. ë‚ ì§œ í•„í„°ë§ (ë™ì  target_date ê¸°ì¤€)
            if "flight_date" in df.columns:
                # flight_dateê°€ ë¬¸ìì—´ì¸ ê²½ìš° datetimeìœ¼ë¡œ ë³€í™˜
                if df["flight_date"].dtype == "object":
                    df["flight_date"] = pd.to_datetime(df["flight_date"])

                # ë™ì  target_dateë¡œ í•„í„°ë§
                target_dt = pd.to_datetime(target_date)
                df = df[df["flight_date"].dt.date == target_dt.date()]
                logger.info(f"ë‚ ì§œ í•„í„°ë§ ({target_date}): {len(df):,}ê°œ")
            else:
                logger.warning("flight_date ì»¬ëŸ¼ì´ ì—†ì–´ ë‚ ì§œ í•„í„°ë§ ìƒëµ")

            # 2. ì¶œë°œê³µí•­ í•„í„°ë§ (ë™ì  departure_airport ê¸°ì¤€)
            if "departure_airport_iata" in df.columns:
                df = df[df["departure_airport_iata"] == departure_airport]
                logger.info(f"ì¶œë°œê³µí•­ í•„í„°ë§ ({departure_airport}): {len(df):,}ê°œ")
            else:
                logger.warning(
                    "departure_airport_iata ì»¬ëŸ¼ì´ ì—†ì–´ ì¶œë°œê³µí•­ í•„í„°ë§ ìƒëµ"
                )

            # 3. ì¢Œì„ìˆ˜ í•„í„°ë§ (total_seats > 0ì¸ ì—¬ê°ê¸°ë§Œ)
            if "total_seats" in df.columns:
                df = df[(df["total_seats"] > 0) & (df["total_seats"].notna())]
                logger.info(f"ì—¬ê°ê¸° í•„í„°ë§ (total_seats > 0): {len(df):,}ê°œ")
            else:
                logger.warning("total_seats ì»¬ëŸ¼ì´ ì—†ì–´ ì¢Œì„ìˆ˜ í•„í„°ë§ ìƒëµ")

            # 4. ì‹œê°„ ì •ë³´ ì™„ì„±ì„± í•„í„°ë§ (ëª¨ë“  ì‹œê°„ ì»¬ëŸ¼ì´ ì¡´ì¬í•´ì•¼ í•¨)
            datetime_cols = [
                "scheduled_departure_local",
                "scheduled_departure_utc",
                "scheduled_arrival_local",
                "scheduled_arrival_utc",
            ]

            existing_datetime_cols = [col for col in datetime_cols if col in df.columns]
            if existing_datetime_cols:
                # ëª¨ë“  datetime ì»¬ëŸ¼ì´ nullì´ ì•„ë‹Œ í–‰ë§Œ ìœ ì§€
                for col in existing_datetime_cols:
                    df = df[df[col].notna()]
                logger.info(
                    f"ì‹œê°„ì •ë³´ ì™„ì„± í•„í„°ë§ ({len(existing_datetime_cols)}ê°œ ì»¬ëŸ¼): {len(df):,}ê°œ"
                )
            else:
                logger.warning("ì‹œê°„ ì»¬ëŸ¼ì´ ì—†ì–´ ì‹œê°„ì •ë³´ í•„í„°ë§ ìƒëµ")

            return df.to_dict("records")
        except Exception as e:
            logger.error(f"Failed to load flight data from S3: {str(e)}")
            return None

    async def _expand_flights_to_passengers(
        self, flight_df: pd.DataFrame, load_factor: float
    ) -> pd.DataFrame:
        """í•­ê³µí¸ì„ ìŠ¹ê° ìˆ˜ë§Œí¼ í™•ì¥"""
        pax_rows = []

        for _, flight_row in flight_df.iterrows():
            pax_count = int(flight_row["total_seats"] * load_factor)

            if pax_count <= 0:
                continue

            for i in range(pax_count):
                pax_row = flight_row.copy()
                pax_rows.append(pax_row)

        result_df = pd.DataFrame(pax_rows)
        logger.info(f"Expanded flights to {len(result_df):,} passenger rows")
        return result_df

    async def _assign_passenger_demographics(
        self, pax_df: pd.DataFrame, config: Dict
    ) -> pd.DataFrame:
        """ìŠ¹ê° ì¸êµ¬í†µê³„ í• ë‹¹"""
        pax_demographics = config.get("pax_demographics", {})

        for distribution_type in pax_demographics.keys():
            column_name = distribution_type.replace("_distribution", "")
            logger.info(f"Assigning {column_name} demographics...")

            pax_df[column_name] = pax_df.apply(
                lambda row: self._assign_demographic_value(
                    row,
                    distribution_type,
                    distribution_config=pax_demographics[distribution_type],
                ),
                axis=1,
            )

        return pax_df

    def _assign_demographic_value(
        self, pax_row: pd.Series, distribution_type: str, distribution_config: Dict
    ) -> str:
        """ê°œë³„ ìŠ¹ê°ì˜ ì¸êµ¬í†µê³„ ê°’ í• ë‹¹"""
        rules = distribution_config.get("rules", [])

        # ì¡°ê±´ í™•ì¸
        for rule in rules:
            conditions = rule.get("conditions", {})
            if self._check_conditions(pax_row, conditions):
                # ë¶„í¬ì— ë”°ë¼ ê°’ ì„ íƒ
                distribution = rule.get("distribution", {})
                if distribution:
                    values = list(distribution.keys())
                    probs = list(distribution.values())
                    return np.random.choice(values, p=probs)

        # ê¸°ë³¸ê°’ ì²˜ë¦¬
        default = distribution_config.get("default", {})
        if default:
            values = list(default.keys())
            probs = list(default.values())
            return np.random.choice(values, p=probs)

        # ë¹ˆ defaultì¸ ê²½ìš° ì²« ë²ˆì§¸ ê·œì¹™ì˜ ë¶„í¬ë¥¼ ì‚¬ìš©
        if rules:
            first_rule = rules[0]
            distribution = first_rule.get("distribution", {})
            if distribution:
                values = list(distribution.keys())
                probs = list(distribution.values())
                return np.random.choice(values, p=probs)

        return "Unknown"

    async def _assign_show_up_times(
        self, pax_df: pd.DataFrame, config: Dict
    ) -> pd.DataFrame:
        """ìŠ¹ê°ë³„ ê³µí•­ ë„ì°©ì‹œê°„ í• ë‹¹"""
        pax_df["show_up_time"] = pax_df.apply(
            lambda row: self._generate_show_up_time(row, config), axis=1
        )

        return pax_df

    def _generate_show_up_time(self, pax_row: pd.Series, config: Dict) -> datetime:
        """ê°œë³„ ìŠ¹ê°ì˜ ê³µí•­ ë„ì°©ì‹œê°„ ìƒì„±"""
        rule = self._match_arrival_rule(pax_row, config)

        if rule:
            mean = rule["mean"]
            std = rule["std"]
        else:
            default = config["pax_arrival_patterns"]["default"]
            mean = default["mean"]
            std = default["std"]

        # ì •ê·œë¶„í¬ì—ì„œ ë„ì°©ì‹œê°„ ìƒì„±
        minutes_before = np.random.normal(mean, std)

        # min_arrival_minutes í•„ìˆ˜ ì…ë ¥ê°’ ê²€ì¦
        min_minutes = config.get("settings", {}).get("min_arrival_minutes")
        if min_minutes is None:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="min_arrival_minutes is required in settings",
            )
        minutes_before = max(minutes_before, min_minutes)

        departure_time = pd.to_datetime(pax_row["scheduled_departure_local"])
        show_up_time = departure_time - timedelta(minutes=minutes_before)

        return show_up_time.replace(microsecond=0)

    async def _save_passenger_data_to_s3(self, pax_df: pd.DataFrame, scenario_id: str):
        """ìŠ¹ê° ë°ì´í„°ë¥¼ S3ì— ì €ì¥"""
        try:
            wr.s3.to_parquet(
                df=pax_df,
                path=f"s3://{get_secret('AWS_S3_BUCKET_NAME')}/{scenario_id}/show-up-passenger.parquet",
                boto3_session=boto3_session,
            )
            logger.info(f"Saved {len(pax_df):,} passenger records to S3")
        except Exception as e:
            logger.error(f"Failed to save passenger data to S3: {str(e)}")
            raise

    async def _build_passenger_schedule_response(
        self, pax_df: pd.DataFrame, config: Dict
    ) -> Dict:
        """ìŠ¹ê° ìŠ¤ì¼€ì¤„ ì‘ë‹µ ë°ì´í„° êµ¬ì„± - ì›ë³¸ê³¼ ë™ì¼í•œ í˜•íƒœ"""

        # Summary ë°ì´í„° ìƒì„± (ì›ë³¸ê³¼ ë™ì¼)
        if len(pax_df) > 0:
            # í•­ê³µí¸ ì •ë³´ì—ì„œ í†µê³„ ê³„ì‚°
            unique_flights = pax_df.drop_duplicates(
                subset=["flight_number", "flight_date"]
            )
            average_seats = (
                unique_flights["total_seats"].mean() if len(unique_flights) > 0 else 0
            )
            total_flights = len(unique_flights)
        else:
            average_seats = 0
            total_flights = 0

        summary = {
            "flights": total_flights,
            "avg_seats": round(average_seats, 2),
            "load_factor": int(config["settings"]["load_factor"] * 100),  # 85 í˜•íƒœë¡œ
        }

        # ì°¨íŠ¸ ë°ì´í„° ìƒì„± (ì›ë³¸ ë¡œì§ê³¼ ë™ì¼)
        chart_result = {}
        chart_x_data = []

        if len(pax_df) > 0:
            # ì£¼ìš” ê·¸ë£¹ ì»¬ëŸ¼ë“¤ (ì›ë³¸ê³¼ ë™ì¼)
            group_columns = [
                "operating_carrier_name",
                "departure_terminal",
                "flight_type",
                "arrival_country_code",
                "arrival_region",
            ]
            group_labels = ["airline", "terminal", "type", "country", "region"]

            for i, group_column in enumerate(group_columns):
                if group_column in pax_df.columns:
                    chart_data = await self._create_show_up_summary(
                        pax_df, group_column
                    )
                    if chart_data:
                        chart_result[group_labels[i]] = chart_data["traces"]
                        chart_x_data = chart_data["default_x"]

        return {
            "total": len(pax_df),
            "summary": summary,
            "bar_chart_x_data": chart_x_data,
            "bar_chart_y_data": chart_result,
            "generation_config": {
                "load_factor": config["settings"]["load_factor"],
                "target_date": config["settings"]["target_date"],
                "departure_airport": config["settings"]["departure_airport"],
                "min_arrival_minutes": config["settings"]["min_arrival_minutes"],
                "generated_at": datetime.now().isoformat(),
            },
        }

    # =====================================
    # Helper Utility Methods
    # =====================================

    def _check_conditions(self, pax_row: pd.Series, conditions: Dict) -> bool:
        """ìŠ¹ê° í–‰ì´ ì£¼ì–´ì§„ ì¡°ê±´ë“¤ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸ - ë³µì¡í•œ ì¡°ê±´ ì§€ì›"""
        for key, values in conditions.items():
            if key == "total_seats":
                # ì¢Œì„ìˆ˜ ë²”ìœ„ ì¡°ê±´ ì²˜ë¦¬ (ì—¬ëŸ¬ ë²”ìœ„ ì§€ì›)
                if "total_seats" in pax_row:
                    seat_count = pax_row["total_seats"]
                    if isinstance(values, list):
                        # ì—¬ëŸ¬ ë²”ìœ„ ì¤‘ í•˜ë‚˜ë¼ë„ ë§¤ì¹˜ë˜ë©´ í†µê³¼
                        range_match = False
                        for range_condition in values:
                            if isinstance(range_condition, dict):
                                min_val = range_condition.get("min", 0)
                                max_val = range_condition.get("max", float("inf"))
                                if min_val <= seat_count <= max_val:
                                    range_match = True
                                    break
                            else:
                                # ë‹¨ìˆœ ê°’ì¸ ê²½ìš° (ê¸°ì¡´ í˜¸í™˜ì„±)
                                if seat_count == range_condition:
                                    range_match = True
                                    break
                        if not range_match:
                            return False
                    elif isinstance(values, dict) and (
                        "min" in values or "max" in values
                    ):
                        # ë‹¨ì¼ ë²”ìœ„ ì¡°ê±´
                        min_val = values.get("min", 0)
                        max_val = values.get("max", float("inf"))
                        if not (min_val <= seat_count <= max_val):
                            return False
                else:
                    continue

            elif key == "scheduled_departure_local_hour":
                # ì¶œë°œì‹œê°„ local hour ì¡°ê±´ ì²˜ë¦¬ - departure_hour ì»¬ëŸ¼ ìš°ì„  ì‚¬ìš©
                if "departure_hour" in pax_row:
                    hour = pax_row["departure_hour"]
                    if hour not in values:
                        return False
                elif "scheduled_departure_local" in pax_row:
                    departure_time = pd.to_datetime(
                        pax_row["scheduled_departure_local"]
                    )
                    hour = departure_time.hour
                    if hour not in values:
                        return False
                else:
                    continue

            elif key == "scheduled_departure_utc_hour":
                # ì¶œë°œì‹œê°„ UTC hour ì¡°ê±´ ì²˜ë¦¬
                if "scheduled_departure_utc" in pax_row:
                    departure_time = pd.to_datetime(pax_row["scheduled_departure_utc"])
                    hour = departure_time.hour
                    if hour not in values:
                        return False
                else:
                    continue

            elif key == "arrival_country":
                # arrival_country ì¡°ê±´ì„ destination_countryì™€ ë§¤ì¹­
                if "destination_country" in pax_row:
                    if isinstance(values, list):
                        if pax_row["destination_country"] not in values:
                            return False
                    else:
                        if pax_row["destination_country"] != values:
                            return False
                else:
                    continue

            elif key == "route":
                # routeëŠ” ì¤‘ì²© êµ¬ì¡° ì²˜ë¦¬ (ê¸°ì¡´ í˜¸í™˜ì„±)
                route_match = False
                for route_key, route_values in values.items():
                    if route_key in pax_row and pax_row[route_key] in route_values:
                        route_match = True
                        break
                if not route_match:
                    return False

            else:
                # ì¼ë°˜ ì¡°ê±´ ì²˜ë¦¬
                if key in pax_row:
                    if isinstance(values, list):
                        if pax_row[key] not in values:
                            return False
                    elif isinstance(values, dict):
                        # ë²”ìœ„ ì¡°ê±´ ì²˜ë¦¬ (ë‹¤ë¥¸ ìˆ«ì ì»¬ëŸ¼ìš©)
                        if "min" in values and "max" in values:
                            if not (values["min"] <= pax_row[key] <= values["max"]):
                                return False
                    else:
                        if pax_row[key] != values:
                            return False
                else:
                    # ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ í•´ë‹¹ ì¡°ê±´ì€ ìŠ¤í‚µ
                    continue

        return True

    def _match_arrival_rule(self, pax_row: pd.Series, config: Dict) -> Optional[Dict]:
        """ìŠ¹ê°ì— ë§ëŠ” ë„ì°© íŒ¨í„´ ê·œì¹™ì„ ì°¾ìŒ"""
        arrival_patterns = config.get("pax_arrival_patterns", {})
        rules = arrival_patterns.get("rules", [])

        for rule in rules:
            conditions = rule.get("conditions", {})
            if self._check_conditions(pax_row, conditions):
                return {"mean": rule.get("mean"), "std": rule.get("std")}

        return None

    async def _create_show_up_summary(self, pax_df: pd.DataFrame, group_column: str):
        """ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ì‹œê°„ ë²”ìœ„ë§Œ í‘œì‹œí•˜ë„ë¡ ê°œì„ ëœ ì°¨íŠ¸ ë°ì´í„° ìƒì„±"""
        time_unit = "10min"
        pax_df_copy = pax_df.copy()
        pax_df_copy["show_up_time"] = pax_df_copy["show_up_time"].dt.floor(time_unit)

        df_grouped = (
            pax_df_copy.groupby(["show_up_time", group_column])
            .size()
            .unstack(fill_value=0)
        )
        df_grouped = df_grouped.sort_index()

        if df_grouped.empty:
            return {"traces": [], "default_x": []}

        # ğŸ”¥ í•µì‹¬ ìˆ˜ì •: ì‹¤ì œ ìŠ¹ê°ì´ ìˆëŠ” ì‹œê°„ ë²”ìœ„ë§Œ ê³„ì‚°
        # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ìŠ¹ê°ì´ ìˆëŠ” ì‹œê°„ì„ ì°¾ìŒ
        row_sums = df_grouped.sum(axis=1)
        non_zero_indices = row_sums[row_sums > 0].index

        if len(non_zero_indices) == 0:
            return {"traces": [], "default_x": []}

        # ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ì‹œê°„ ë²”ìœ„ë¡œ í•„í„°ë§
        start_time = non_zero_indices.min()
        end_time = non_zero_indices.max()
        df_grouped = df_grouped.loc[start_time:end_time]

        total_groups = df_grouped.shape[1]
        has_etc = total_groups > 9

        if has_etc:
            top_9_columns = df_grouped.sum().nlargest(9).index.tolist()
            df_grouped["etc"] = df_grouped.drop(
                columns=top_9_columns, errors="ignore"
            ).sum(axis=1)
            df_grouped = df_grouped[top_9_columns + ["etc"]]
        else:
            top_9_columns = df_grouped.columns.tolist()

        group_order = df_grouped.sum().sort_values(ascending=False).index.tolist()
        if has_etc and "etc" in group_order:
            group_order.remove("etc")
            group_order.append("etc")

        default_x = df_grouped.index.strftime("%H:%M").tolist()
        traces = [
            {
                "name": column,
                "order": group_order.index(column),
                "y": df_grouped[column].tolist(),
            }
            for column in df_grouped.columns
        ]

        return {"traces": traces, "default_x": default_x}
