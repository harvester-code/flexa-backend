"""
ìŠ¹ê° ìœ ì…ëŸ‰ ë¶„ì„ Core ëª¨ë“ˆ

í”„ë¡œì„¸ìŠ¤ íë¦„ ê¸°ë°˜ìœ¼ë¡œ ê° ì‹œì„¤ë³„ 15ë¶„ ê°„ê²© ìŠ¹ê° ìœ ì…ëŸ‰ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
S3ì˜ show-up-passenger.parquet íŒŒì¼ê³¼ ì—°ê³„í•˜ì—¬ ì‹¤ì œ ìŠ¹ê° ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. S3 parquet ë°ì´í„° ë¡œë“œ
2. í”„ë¡œì„¸ìŠ¤ íë¦„ íŒŒì‹± ë° ì‹œì„¤ ê·¸ë£¹ ìƒì„±  
3. travel_time ëˆ„ì  ê³„ì‚°ìœ¼ë¡œ ê° ì‹œì„¤ ë„ì°© ì‹œê°„ ì‚°ì¶œ
4. 15ë¶„ ë‹¨ìœ„ ì‹œê°„ ê·¸ë£¹í•‘í•˜ì—¬ ì‹œì„¤ë³„ ìŠ¹ê° ìˆ˜ ì§‘ê³„
5. ì‘ë‹µ JSON ìƒì„±
"""

from datetime import datetime, timedelta
from typing import Any, Dict, List

from fastapi import HTTPException, status
from loguru import logger


class PassengerInflowAnalyzer:
    """ìŠ¹ê° ìœ ì…ëŸ‰ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        pass
    
    async def analyze_passenger_inflow(
        self, scenario_id: str, process_flow: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        ìŠ¹ê° ìœ ì…ëŸ‰ ë¶„ì„ - í”„ë¡œì„¸ìŠ¤ íë¦„ ê¸°ë°˜ ì‹œì„¤ë³„ ì‹œê°„ëŒ€ ë¶„ì„
        
        Args:
            scenario_id: ì‹œë‚˜ë¦¬ì˜¤ UUID
            process_flow: ê³µí•­ í”„ë¡œì„¸ìŠ¤ ë‹¨ê³„ë³„ ì„¤ì • ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì‹œê°„ëŒ€ë³„ ì‹œì„¤ ê·¸ë£¹ë³„ ìŠ¹ê° ìœ ì…ëŸ‰ ë°ì´í„°
            
        Raises:
            HTTPException: S3 parquet ì½ê¸° ì‹¤íŒ¨, ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜ ì‹œ
        """
        try:
            logger.info(f"ğŸ” ìŠ¹ê° ìœ ì…ëŸ‰ ë¶„ì„ ì‹œì‘ (ë™ì  ê·¸ë£¹í•‘): scenario_id={scenario_id}")
            
            # 1ë‹¨ê³„: S3ì—ì„œ ìŠ¹ê° ë°ì´í„° ë¡œë“œ
            passenger_df = await self._load_passenger_data_from_s3(scenario_id)
            
            # 2ë‹¨ê³„: í”„ë¡œì„¸ìŠ¤ íë¦„ íŒŒì‹±í•˜ì—¬ ê°œë³„ ì‹œì„¤ ì •ë³´ ìƒì„±
            facilities_by_process = self._parse_process_flow_to_facilities(process_flow)
            
            # 3ë‹¨ê³„: 15ë¶„ ê°„ê²© ë™ì  ê·¸ë£¹í•‘ìœ¼ë¡œ ìŠ¹ê° ìˆ˜ ì§‘ê³„
            time_grouped_data, missing_passengers_data = self._group_by_15min_intervals(
                passenger_df, facilities_by_process
            )
            
            # 4ë‹¨ê³„: ì‘ë‹µ JSON í˜•íƒœë¡œ ë³€í™˜
            response_data = self._build_passenger_inflow_response(
                scenario_id, time_grouped_data, missing_passengers_data, int(len(passenger_df))  # âœ… numpy íƒ€ì… ë°©ì§€
            )
            
            logger.info(f"âœ… ë™ì  ê·¸ë£¹í•‘ ë¶„ì„ ì™„ë£Œ: scenario_id={scenario_id}")
            return response_data
            
        except Exception as e:
            logger.error(f"âŒ ìŠ¹ê° ìœ ì…ëŸ‰ ë¶„ì„ ì‹¤íŒ¨: scenario_id={scenario_id}, error={str(e)}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Failed to analyze passenger inflow: {str(e)}",
            )

    async def _load_passenger_data_from_s3(self, scenario_id: str):
        """S3ì—ì„œ ìŠ¹ê° parquet ë°ì´í„° ë¡œë“œ"""
        try:
            # TODO: S3Managerë¥¼ ì‚¬ìš©í•˜ì—¬ show-up-passenger.parquet ë¡œë“œ
            # ì„ì‹œë¡œ ë¡œì»¬ parquet íŒŒì¼ ë¡œë“œ (ê°œë°œìš©)
            import pandas as pd
            
            # S3 ê²½ë¡œ êµ¬ì„±
            s3_path = f"s3://your-bucket/scenario-data/{scenario_id}/show-up-passenger.parquet"
            
            # ê°œë°œìš©: ë¡œì»¬ íŒŒì¼ ì‚¬ìš©
            local_path = "/Users/yi/Desktop/flexa/show-up-passenger.parquet"
            passenger_df = pd.read_parquet(local_path)
            
            logger.info(f"ğŸ“Š ìŠ¹ê° ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(passenger_df):,}ëª…")
            return passenger_df
            
        except Exception as e:
            logger.error(f"âŒ S3 ìŠ¹ê° ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Passenger data not found for scenario {scenario_id}",
            )

    def _parse_process_flow_to_facilities(self, process_flow: List[Dict[str, Any]]) -> Dict[str, Any]:
        """í”„ë¡œì„¸ìŠ¤ íë¦„ì„ íŒŒì‹±í•˜ì—¬ ê°œë³„ ì‹œì„¤ ì •ë³´ ìƒì„± (ë™ì  ê·¸ë£¹í•‘ ì¤€ë¹„)"""
        try:
            facilities_by_process = {}
            cumulative_travel_time = 0
            
            for step_data in process_flow:
                process_name = step_data.get("name", f"process_{step_data.get('step', 0)}")
                travel_time = step_data.get("travel_time_minutes", 0)
                cumulative_travel_time += travel_time
                
                zones = step_data.get("zones", {})
                process_facilities = []
                
                for zone_name, zone_data in zones.items():
                    facilities = zone_data.get("facilities", [])
                    
                    for facility in facilities:
                        if facility.get("id"):
                            process_facilities.append({
                                "id": facility["id"],
                                "zone_name": zone_name,
                                "operating_schedule": facility.get("operating_schedule", {}),
                                "facility_data": facility,
                            })
                
                if process_facilities:
                    facilities_by_process[process_name] = {
                        "arrival_time_offset": cumulative_travel_time,
                        "entry_conditions": step_data.get("entry_conditions", []),
                        "facilities": process_facilities,
                    }
                    
                    logger.info(f"ğŸ­ í”„ë¡œì„¸ìŠ¤ íŒŒì‹±: {process_name} â†’ {len(process_facilities)}ê°œ ì‹œì„¤")
            
            logger.info(f"ğŸ“Š ì‹œì„¤ íŒŒì‹± ì™„ë£Œ: {len(facilities_by_process)}ê°œ í”„ë¡œì„¸ìŠ¤")
            return facilities_by_process
            
        except Exception as e:
            logger.error(f"âŒ í”„ë¡œì„¸ìŠ¤ íë¦„ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            raise

    def _get_facility_conditions_for_time(self, facility: Dict[str, Any], target_time_str: str) -> Dict[str, Any]:
        """íŠ¹ì • ì‹œê°„ì— ì‹œì„¤ì˜ ìš´ì˜ ìƒíƒœì™€ ìŠ¹ê° ì¡°ê±´ì„ ê°€ì ¸ì˜¤ê¸°"""
        try:
            operating_schedule = facility.get("operating_schedule", {})
            time_blocks = operating_schedule.get("today", {}).get("time_blocks", [])
            
            # ì‹œê°„ì„ ë¶„ ë‹¨ìœ„ë¡œ ë³€í™˜ (ì˜ˆ: "07:30" -> 450)
            def time_to_minutes(time_str: str) -> int:
                if not time_str or time_str == "24:00":
                    return 24 * 60 if time_str == "24:00" else 0
                try:
                    hours, minutes = time_str.split(":")
                    return int(hours) * 60 + int(minutes)
                except (ValueError, AttributeError):
                    logger.error(f"âŒ ì‹œê°„ í˜•ì‹ ì˜¤ë¥˜: '{time_str}' - 00:00ìœ¼ë¡œ ì²˜ë¦¬")
                    return 0
            
            target_minutes = time_to_minutes(target_time_str)
            
            # í•´ë‹¹ ì‹œê°„ëŒ€ì˜ ì¡°ê±´ ì°¾ê¸°
            for block in time_blocks:
                period = block.get("period", "")
                if "-" in period:
                    start_time, end_time = period.split("-")
                    start_minutes = time_to_minutes(start_time)
                    end_minutes = time_to_minutes(end_time)
                    
                    # 24:00 ì²˜ë¦¬ (1440ë¶„)
                    if end_minutes == 0 and end_time != "00:00":
                        end_minutes = 24 * 60
                    
                    # ì‹œê°„ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
                    if start_minutes <= target_minutes < end_minutes:
                        return {
                            "is_operating": True,
                            "passenger_conditions": block.get("passenger_conditions", []),
                            "process_time_seconds": block.get("process_time_seconds", 0),
                        }
            
            # ì–´ë–¤ time_blockì—ë„ í¬í•¨ë˜ì§€ ì•Šìœ¼ë©´ ìš´ì˜ ì¤‘ë‹¨
            return {
                "is_operating": False,
                "passenger_conditions": [],
                "process_time_seconds": 0,
            }
            
        except Exception as e:
            logger.error(f"âŒ ì‹œì„¤ ì¡°ê±´ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
            return {
                "is_operating": False,
                "passenger_conditions": [],
                "process_time_seconds": 0,
            }

    def _create_dynamic_groups_for_time_slot(self, facilities_by_process: Dict[str, Any], time_slot_str: str) -> Dict[str, Any]:
        """íŠ¹ì • ì‹œê°„ëŒ€ì— ëŒ€í•´ ì‹œì„¤ë“¤ì„ ë™ì ìœ¼ë¡œ ê·¸ë£¹í•‘"""
        try:
            dynamic_groups = {}
            
            for process_name, process_info in facilities_by_process.items():
                facilities = process_info["facilities"]
                arrival_time_offset = process_info["arrival_time_offset"]
                entry_conditions = process_info["entry_conditions"]
                
                # ì‹œì„¤ë³„ ì¡°ê±´ ìˆ˜ì§‘
                facility_conditions = {}
                for facility in facilities:
                    facility_id = facility["id"]
                    conditions = self._get_facility_conditions_for_time(facility, time_slot_str)
                    facility_conditions[facility_id] = conditions
                
                # ğŸ”¥ í•µì‹¬: ë™ì¼í•œ ì¡°ê±´ì„ ê°€ì§„ ì‹œì„¤ë“¤ì„ ê·¸ë£¹í•‘
                condition_groups = {}
                for facility_id, conditions in facility_conditions.items():
                    if not conditions["is_operating"]:
                        continue  # ë¹„í™œì„±í™”ëœ ì‹œì„¤ì€ ê·¸ë£¹ì—ì„œ ì œì™¸
                    
                    # ì¡°ê±´ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ê·¸ë£¹ í‚¤ ìƒì„±
                    passenger_conditions = conditions["passenger_conditions"]
                    condition_key = self._serialize_conditions(passenger_conditions)
                    
                    if condition_key not in condition_groups:
                        condition_groups[condition_key] = {
                            "facilities": [],
                            "passenger_conditions": passenger_conditions,
                            "process_time_seconds": conditions["process_time_seconds"],
                        }
                    
                    condition_groups[condition_key]["facilities"].append(facility_id)
                
                # ê° ì¡°ê±´ ê·¸ë£¹ì„ ë™ì  ê·¸ë£¹ìœ¼ë¡œ ë³€í™˜
                for condition_key, group_data in condition_groups.items():
                    facility_ids = group_data["facilities"]
                    
                    # ê·¸ë£¹ í‚¤ ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼í•œ ë°©ì‹)
                    if len(facility_ids) == 1:
                        group_key = facility_ids[0]
                    else:
                        group_key = f"{facility_ids[0]}~{facility_ids[-1]}"
                    
                    dynamic_groups[group_key] = {
                        "process_name": process_name,
                        "facility_ids": facility_ids,
                        "arrival_time_offset": arrival_time_offset,
                        "entry_conditions": entry_conditions,
                        "passenger_conditions": group_data["passenger_conditions"],
                        "process_time_seconds": group_data["process_time_seconds"],
                    }
                    
                    logger.debug(f"ğŸ¯ ë™ì  ê·¸ë£¹: {process_name} â†’ {group_key} ({len(facility_ids)}ê°œ ì‹œì„¤, ì¡°ê±´: {condition_key})")
            
            return dynamic_groups
            
        except Exception as e:
            logger.error(f"âŒ ë™ì  ê·¸ë£¹ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise

    def _serialize_conditions(self, passenger_conditions: List[Dict[str, Any]]) -> str:
        """ìŠ¹ê° ì¡°ê±´ì„ ì •ë ¬ ê°€ëŠ¥í•œ ë¬¸ìì—´ë¡œ ì§ë ¬í™”"""
        try:
            if not passenger_conditions:
                return "no_conditions"
            
            # ì¡°ê±´ì„ ì •ë ¬í•˜ì—¬ ì¼ê´€ì„± í™•ë³´
            sorted_conditions = sorted(passenger_conditions, key=lambda x: (x.get("field", ""), str(x.get("values", []))))
            
            condition_parts = []
            for condition in sorted_conditions:
                field = condition.get("field", "")
                values = sorted(condition.get("values", []))  # ê°’ë„ ì •ë ¬
                condition_parts.append(f"{field}:{','.join(values)}")
            
            return "|".join(condition_parts)
            
        except Exception as e:
            logger.error(f"âŒ ì¡°ê±´ ì§ë ¬í™” ì‹¤íŒ¨: {str(e)}")
            return "error_condition"

    def _group_by_15min_intervals(self, passenger_df, facilities_by_process: Dict[str, Any]):
        """15ë¶„ ê°„ê²©ìœ¼ë¡œ ë™ì  ê·¸ë£¹ë³„ ìŠ¹ê° ìˆ˜ ì§‘ê³„"""
        try:
            import pandas as pd
            
            # ì „ì²´ ì‹œê°„ ë²”ìœ„ íŒŒì•… (ëª¨ë“  í”„ë¡œì„¸ìŠ¤ì˜ ìŠ¹ê° ë„ì°© ì‹œê°„)
            all_times = []
            all_arrival_data = {}
            
            # ê° í”„ë¡œì„¸ìŠ¤ë³„ë¡œ ìŠ¹ê° ë„ì°© ì‹œê°„ ê³„ì‚°
            for process_name, process_info in facilities_by_process.items():
                arrival_offset = pd.Timedelta(minutes=process_info["arrival_time_offset"])
                process_passenger_df = passenger_df.copy()
                process_passenger_df["facility_arrival_time"] = process_passenger_df["show_up_time"] + arrival_offset
                
                all_times.extend(process_passenger_df["facility_arrival_time"].tolist())
                all_arrival_data[process_name] = process_passenger_df
            
            if not all_times:
                return [], []
            
            min_time = min(all_times)
            max_time = max(all_times)
            
            # 15ë¶„ ê°„ê²© ì‹œê°„ëŒ€ ìƒì„±
            time_intervals = []
            current_time = min_time.floor('15min')  # 15ë¶„ ë‹¨ìœ„ë¡œ ë‚´ë¦¼
            
            while current_time <= max_time.ceil('15min'):
                time_intervals.append(current_time)
                current_time += timedelta(minutes=15)
            
            # ê° ì‹œê°„ëŒ€ë³„ë¡œ ë™ì  ê·¸ë£¹ ìƒì„± ë° ìŠ¹ê°ìˆ˜ ì§‘ê³„
            time_grouped_data = []
            missing_passengers_data = []
            
            for time_slot in time_intervals:
                next_time_slot = time_slot + timedelta(minutes=15)
                time_slot_str = time_slot.strftime("%H:%M")  # ì‹œì„¤ ìš´ì˜ì‹œê°„ ë¹„êµìš©
                
                # ğŸ”¥ í•´ë‹¹ ì‹œê°„ëŒ€ì— ëŒ€í•œ ë™ì  ê·¸ë£¹ ìƒì„±
                dynamic_groups = self._create_dynamic_groups_for_time_slot(facilities_by_process, time_slot_str)
                
                time_groups = {}
                missing_groups = {}
                
                # ê° ë™ì  ê·¸ë£¹ë³„ë¡œ ìŠ¹ê° ìˆ˜ ê³„ì‚°
                for group_key, group_info in dynamic_groups.items():
                    process_name = group_info["process_name"]
                    
                    # í•´ë‹¹ í”„ë¡œì„¸ìŠ¤ì˜ ìŠ¹ê° ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    if process_name not in all_arrival_data:
                        continue
                        
                    passenger_df_process = all_arrival_data[process_name]
                    
                    # í•´ë‹¹ ì‹œê°„ëŒ€ì— ë„ì°©í•˜ëŠ” ìŠ¹ê° ìˆ˜ ê³„ì‚°
                    mask = (
                        (passenger_df_process["facility_arrival_time"] >= time_slot) &
                        (passenger_df_process["facility_arrival_time"] < next_time_slot)
                    )
                    passenger_count = int(mask.sum())  # âœ… numpy.int64 â†’ Python int ë³€í™˜
                    
                    if passenger_count > 0:
                        # í”„ë¡œì„¸ìŠ¤ë³„ë¡œ ê·¸ë£¹ ì •ë¦¬
                        if process_name not in time_groups:
                            time_groups[process_name] = {}
                        
                        time_groups[process_name][group_key] = passenger_count
                        
                        logger.debug(f"ğŸ¯ ë™ì  ì§‘ê³„: {process_name}/{group_key} â†’ {passenger_count}ëª… @ {time_slot_str}")
                
                # TODO: ë¯¸ì²˜ë¦¬ ìŠ¹ê° ë¡œì§ (2ë‹¨ê³„ì—ì„œ êµ¬í˜„)
                # í˜„ì¬ëŠ” ëª¨ë“  ìŠ¹ê°ì´ ì²˜ë¦¬ë˜ëŠ” ê²ƒìœ¼ë¡œ ê°€ì •
                
                # ë¹ˆ í”„ë¡œì„¸ìŠ¤ ì œê±°
                time_groups = {
                    process: groups for process, groups in time_groups.items() 
                    if groups  # ë¹ˆ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ
                }
                
                # ì •ìƒ ì²˜ë¦¬ëœ ìŠ¹ê° ë°ì´í„° ì¶”ê°€
                if time_groups:
                    time_grouped_data.append({
                        "time": time_slot.strftime("%Y-%m-%d %H:%M"),
                        "groups": time_groups
                    })
            
            logger.info(f"ğŸ“Š ë™ì  ê·¸ë£¹í•‘ ì™„ë£Œ: {len(time_grouped_data)}ê°œ êµ¬ê°„")
            return time_grouped_data, missing_passengers_data
            
        except Exception as e:
            logger.error(f"âŒ ë™ì  ê·¸ë£¹í•‘ ì‹¤íŒ¨: {str(e)}")
            raise

    def _build_passenger_inflow_response(
        self, scenario_id: str, time_grouped_data: List[Dict], missing_passengers_data: List[Dict], total_passengers: int
    ) -> Dict[str, Any]:
        """ìµœì¢… ì‘ë‹µ JSON ìƒì„± (missing_passengers í¬í•¨)"""
        try:
            # ë¶„ì„ ê¸°ê°„ ê³„ì‚°
            if time_grouped_data:
                start_time = time_grouped_data[0]["time"]
                end_time = time_grouped_data[-1]["time"]
            else:
                start_time = end_time = datetime.now().strftime("%Y-%m-%d %H:%M")
            
            return {
                "scenario_id": scenario_id,
                "analysis_period": {
                    "start": start_time,
                    "end": end_time,
                    "total_intervals": int(len(time_grouped_data))  # âœ… numpy íƒ€ì… ë°©ì§€
                },
                "total_passengers": int(total_passengers),  # âœ… numpy íƒ€ì… ë°©ì§€ (ì´ì¤‘ ë³´í˜¸)
                "chart_data": time_grouped_data,
                "missing_passengers": missing_passengers_data  # ğŸ†• ë¯¸ì²˜ë¦¬ ìŠ¹ê° ë°ì´í„° ì¶”ê°€
            }
            
        except Exception as e:
            logger.error(f"âŒ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise


class PassengerInflowResponse:
    """ìŠ¹ê° ìœ ì…ëŸ‰ ë¶„ì„ ì‘ë‹µ ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.analyzer = PassengerInflowAnalyzer()
    
    async def build_response(
        self, scenario_id: str, process_flow: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ìŠ¹ê° ìœ ì…ëŸ‰ ë¶„ì„ ì‘ë‹µ ìƒì„±"""
        return await self.analyzer.analyze_passenger_inflow(scenario_id, process_flow)
