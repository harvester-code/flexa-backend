"""
í•­ê³µí¸ ìŠ¤ì¼€ì¤„ ì²˜ë¦¬ í†µí•© ëª¨ë“ˆ (Flight Schedule Processing)

ì´ ëª¨ë“ˆì€ í•­ê³µí¸ ìŠ¤ì¼€ì¤„ ì²˜ë¦¬ì˜ Storageì™€ Response ê¸°ëŠ¥ì„ í†µí•©í•©ë‹ˆë‹¤:
- FlightScheduleStorage: Redshiftì—ì„œ í•­ê³µí¸ ë°ì´í„° ì¡°íšŒ ë° S3 ì €ì¥
- FlightScheduleResponse: í”„ë¡ íŠ¸ì—”ë“œìš© JSON ì‘ë‹µ ìƒì„± (ì°¨íŠ¸ ë°ì´í„° í¬í•¨)
"""

from datetime import datetime
from typing import Dict, List, Optional

import pandas as pd
from fastapi import HTTPException
from loguru import logger
from sqlalchemy import Connection

import awswrangler as wr
from packages.doppler.client import get_secret
from packages.aws.s3.storage import boto3_session, check_s3_object_exists
from app.routes.simulation.application.queries import (
    SELECT_AIRPORT_FLIGHTS_EXTENDED,
    SELECT_AIRPORT_SCHEDULE,
)


class FlightScheduleStorage:
    """í•­ê³µí¸ ìŠ¤ì¼€ì¤„ ë°ì´í„° ì €ì¥ ì „ë‹´ í´ë˜ìŠ¤"""

    async def fetch_and_store(
        self,
        db: Connection,
        date: str,
        airport: str,
        flight_type: str,
        conditions: list | None,
        scenario_id: str,
        storage: str = "redshift",
    ) -> List[dict]:
        """í•­ê³µí¸ ìŠ¤ì¼€ì¤„ ë°ì´í„° ì¡°íšŒ ë° ì €ì¥"""
        try:
            # 1. ì¡°ê±´ ë³€í™˜
            converted_conditions = (
                self._convert_filter_conditions(conditions) if conditions else None
            )

            # 2. ë°ì´í„° ì¡°íšŒ
            flight_schedule_data = await self._fetch_flight_schedule_data(
                db,
                date,
                airport,
                flight_type,
                converted_conditions,
                scenario_id,
                storage,
            )

            # 3. S3 ì €ì¥
            await self._save_flight_schedule_to_s3(flight_schedule_data, scenario_id)

            return flight_schedule_data

        except Exception as e:
            logger.error(f"Flight schedule storage failed: {str(e)}")
            raise HTTPException(
                status_code=500, detail=f"Failed to process flight schedule: {str(e)}"
            )

    async def _fetch_flight_schedule_data(
        self,
        db: Connection,
        date: str,
        airport: str,
        flight_type: str,
        conditions: list | None,
        scenario_id: str,
        storage: str = "s3",
    ):
        """í•­ê³µê¸° ìŠ¤ì¼€ì¤„ ë°ì´í„° ì¡°íšŒ (S3 ìš°ì„ , Redshift ëŒ€ì²´)"""
        flight_schedule_data = None

        # S3 ë°ì´í„° í™•ì¸
        if storage == "s3":
            object_exists = await check_s3_object_exists(
                bucket_name=get_secret("AWS_S3_BUCKET_NAME"),
                object_key=f"{scenario_id}/flight-schedule.parquet",
            )

            if object_exists:
                flight_schedule_data = wr.s3.read_parquet(
                    path=f"s3://{get_secret('AWS_S3_BUCKET_NAME')}/{scenario_id}/flight-schedule.parquet",
                    boto3_session=boto3_session,
                ).to_dict("records")

        # Redshiftì—ì„œ ë°ì´í„° ì¡°íšŒ
        if not flight_schedule_data:
            # ë‚ ì§œì— ë”°ë¥¸ í…Œì´ë¸” ì„ íƒ
            target_date = datetime.strptime(date, "%Y-%m-%d").date()
            today = datetime.now().date()

            if target_date < today:
                # ê³¼ê±° ë°ì´í„°: flights_extended í…Œì´ë¸”
                query = SELECT_AIRPORT_FLIGHTS_EXTENDED
            else:
                # ì˜¤ëŠ˜/ë¯¸ë˜ ë°ì´í„°: schedule í…Œì´ë¸”
                query = SELECT_AIRPORT_SCHEDULE

            # redshift-connectorë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ê²½ê³  ë°©ì§€
            cursor = db.cursor()

            # flight_typeì— ë”°ë¼ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì¡°ì •
            if flight_type == "departure":
                # departure ì „ìš© ì¿¼ë¦¬ë¡œ ìˆ˜ì •
                modified_query = query.replace(
                    "AND (fe.departure_airport_iata = %s OR fe.arrival_airport_iata = %s)",
                    "AND fe.departure_airport_iata = %s",
                ).replace(
                    "AND (s.departure_station_code_iata = %s OR s.arrival_station_code_iata = %s)",
                    "AND s.departure_station_code_iata = %s",
                )
                cursor.execute(modified_query, (date, airport))
            elif flight_type == "arrival":
                # arrival ì „ìš© ì¿¼ë¦¬ë¡œ ìˆ˜ì •
                modified_query = query.replace(
                    "AND (fe.departure_airport_iata = %s OR fe.arrival_airport_iata = %s)",
                    "AND fe.arrival_airport_iata = %s",
                ).replace(
                    "AND (s.departure_station_code_iata = %s OR s.arrival_station_code_iata = %s)",
                    "AND s.arrival_station_code_iata = %s",
                )
                cursor.execute(modified_query, (date, airport))
            else:
                # ê¸°ë³¸ê°’: ê¸°ì¡´ OR ì¡°ê±´ ìœ ì§€
                cursor.execute(query, (date, airport, airport))

            columns = [desc[0] for desc in cursor.description]
            rows = cursor.fetchall()
            cursor.close()

            # DataFrameìœ¼ë¡œ ë³€í™˜
            flight_schedule_df = pd.DataFrame(rows, columns=columns)
            flight_schedule_data = flight_schedule_df.to_dict("records")

            # ì¡°ê±´ í•„í„°ë§ (fieldë“¤ì€ AND, valuesëŠ” OR ì¡°ê±´)
            if conditions:
                filtered_data = []
                for flight in flight_schedule_data:
                    include_flight = True

                    # ëª¨ë“  field ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•¨ (AND ì¡°ê±´)
                    for cond in conditions:
                        field = cond["field"]
                        values = cond["values"]
                        flight_value = flight.get(field)

                        if flight_value is None:
                            include_flight = False
                            break

                        # values ì¤‘ í•˜ë‚˜ë¼ë„ ë§¤ì¹˜ë˜ë©´ ë¨ (OR ì¡°ê±´)
                        if flight_value not in values:
                            include_flight = False
                            break

                    if include_flight:
                        filtered_data.append(flight)

                flight_schedule_data = filtered_data

        return flight_schedule_data

    def _convert_filter_conditions(self, filter_conditions: list) -> list:
        """í•„í„° ì¡°ê±´ì„ ë°ì´í„°ë² ì´ìŠ¤ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë§¤í•‘"""
        if not filter_conditions:
            return []

        field_mapping = {
            "types": "flight_type",
            "terminal": "departure_terminal",  # ê¸°ë³¸ê°’, flight_typeì— ë”°ë¼ ë™ì ìœ¼ë¡œ ë³€ê²½ë¨
            "airline": "operating_carrier_iata",
        }

        converted = []
        for filter_cond in filter_conditions:
            field = (
                filter_cond.get("field")
                if isinstance(filter_cond, dict)
                else filter_cond.field
            )
            values = (
                filter_cond.get("values")
                if isinstance(filter_cond, dict)
                else filter_cond.values
            )

            if mapped_field := field_mapping.get(field):
                converted.append({"field": mapped_field, "values": values})

        return converted

    async def _save_flight_schedule_to_s3(
        self, flight_schedule_data: list, scenario_id: str
    ):
        """S3ì— í•­ê³µí¸ ìŠ¤ì¼€ì¤„ ë°ì´í„° ì €ì¥"""
        if not flight_schedule_data:
            return

        wr.s3.to_parquet(
            df=pd.DataFrame(flight_schedule_data),
            path=f"s3://{get_secret('AWS_S3_BUCKET_NAME')}/{scenario_id}/flight-schedule.parquet",
            boto3_session=boto3_session,
        )


class FlightScheduleResponse:
    """í•­ê³µí¸ ìŠ¤ì¼€ì¤„ í”„ë¡ íŠ¸ì—”ë“œ ì‘ë‹µ ìƒì„± ì „ë‹´ í´ë˜ìŠ¤"""

    async def build_response(
        self,
        flight_schedule_data: list,
        applied_conditions: list | None,
        flight_type: str,
    ) -> dict:
        """í•­ê³µí¸ ìŠ¤ì¼€ì¤„ ì‘ë‹µ ë°ì´í„° êµ¬ì„±"""
        if not flight_schedule_data:
            return self._get_empty_response()

        flight_df = pd.DataFrame(flight_schedule_data)

        # í•­ê³µì‚¬ë³„ íƒ€ì… ë¶„ë¥˜
        types_data = self._build_airline_types(flight_df)

        # í„°ë¯¸ë„ë³„ í•­ê³µì‚¬ ë¶„ë¥˜ (flight_typeì— ë”°ë¼ êµ¬ë¶„)
        terminals_data = self._build_terminal_airlines(flight_df, flight_type)

        # ì°¨íŠ¸ ë°ì´í„° ìƒì„± (flight_typeì— ë”°ë¼ êµ¬ë¶„)
        chart_data = await self._build_chart_data(flight_df, flight_type)

        # Parquet ë©”íƒ€ë°ì´í„° ìƒì„± (Passenger Scheduleì—ì„œ ì‚¬ìš©)
        parquet_metadata = self._build_parquet_metadata(flight_df)

        return {
            "total": len(flight_df),
            "types": types_data,
            "terminals": terminals_data,
            "chart_x_data": chart_data.get("x_data", []),
            "chart_y_data": chart_data.get("y_data", {}),
            "parquet_metadata": parquet_metadata,
        }

    def _get_empty_response(self) -> dict:
        """ë¹ˆ ì‘ë‹µ ë°ì´í„° ë°˜í™˜"""
        return {
            "total": 0,
            "types": {},
            "terminals": {},
            "chart_x_data": [],
            "chart_y_data": {},
            "parquet_metadata": {"columns": []},
        }

    def _build_airline_types(self, flight_df: pd.DataFrame) -> dict:
        """í•­ê³µì‚¬ë³„ íƒ€ì… ë¶„ë¥˜"""
        # í•­ê³µì‚¬ë³„ ê³ ìœ  ë°ì´í„° ì¶”ì¶œ
        airline_df = flight_df[
            ["operating_carrier_iata", "operating_carrier_name", "flight_type"]
        ].drop_duplicates()

        # íƒ€ì…ë³„ í•­ê³µì‚¬ ë¶„ë¥˜
        international_mask = airline_df["flight_type"] == "International"
        domestic_mask = airline_df["flight_type"] == "Domestic"

        international_airlines = (
            airline_df[international_mask][
                ["operating_carrier_iata", "operating_carrier_name"]
            ]
            .rename(
                columns={
                    "operating_carrier_iata": "iata",
                    "operating_carrier_name": "name",
                }
            )
            .to_dict("records")
        )

        domestic_airlines = (
            airline_df[domestic_mask][
                ["operating_carrier_iata", "operating_carrier_name"]
            ]
            .rename(
                columns={
                    "operating_carrier_iata": "iata",
                    "operating_carrier_name": "name",
                }
            )
            .to_dict("records")
        )

        return {
            "International": international_airlines,
            "Domestic": domestic_airlines,
        }

    def _build_terminal_airlines(
        self, flight_df: pd.DataFrame, flight_type: str = "departure"
    ) -> dict:
        """í„°ë¯¸ë„ë³„ í•­ê³µì‚¬ ë¶„ë¥˜ - departure/arrival êµ¬ë¶„"""
        # flight_typeì— ë”°ë¼ ì‚¬ìš©í•  í„°ë¯¸ë„ ì»¬ëŸ¼ ê²°ì •
        terminal_column = f"{flight_type}_terminal"

        if terminal_column not in flight_df.columns:
            return {}

        # í„°ë¯¸ë„ë³„ í•­ê³µì‚¬ ê·¸ë£¹í™” (ì¤‘ë³µ ì œê±°)
        terminal_groups = (
            flight_df[
                [
                    terminal_column,
                    "operating_carrier_iata",
                    "operating_carrier_name",
                ]
            ]
            .fillna({terminal_column: "unknown"})
            .drop_duplicates()
            .groupby(terminal_column)
        )

        terminals = {}
        for terminal, group in terminal_groups:
            airlines = (
                group[["operating_carrier_iata", "operating_carrier_name"]]
                .rename(
                    columns={
                        "operating_carrier_iata": "iata",
                        "operating_carrier_name": "name",
                    }
                )
                .to_dict("records")
            )
            terminals[terminal] = airlines

        return terminals

    async def _build_chart_data(
        self, flight_df: pd.DataFrame, flight_type: str = "departure"
    ) -> dict:
        """ì°¨íŠ¸ ë°ì´í„° ìƒì„± - departure/arrival êµ¬ë¶„"""
        chart_result = {}
        chart_x_data = []

        # flight_typeì— ë”°ë¼ ì‚¬ìš©í•  í„°ë¯¸ë„ ì»¬ëŸ¼ ê²°ì •
        terminal_column = f"{flight_type}_terminal"

        # ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•œ ê·¸ë£¹ ì»¬ëŸ¼ë“¤
        group_columns = [
            "operating_carrier_name",
            terminal_column,
            "flight_type",
            "arrival_country_code",
            "arrival_region",
        ]
        group_labels = ["airline", "terminal", "type", "country", "region"]

        for i, group_column in enumerate(group_columns):
            if group_column in flight_df.columns:
                chart_result_data = await self._create_flight_schedule_chart(
                    flight_df, group_column, flight_type
                )

                if chart_result_data:
                    chart_result[group_labels[i]] = chart_result_data["traces"]
                    chart_x_data = chart_result_data["default_x"]

        return {
            "x_data": chart_x_data,
            "y_data": chart_result,
        }

    async def _create_flight_schedule_chart(
        self, flight_df: pd.DataFrame, group_column: str, flight_type: str = "departure"
    ):
        """í•­ê³µí¸ ìŠ¤ì¼€ì¤„ ì°¨íŠ¸ ë°ì´í„° ìƒì„±"""
        # flight_typeì— ë”°ë¼ ì‚¬ìš©í•  ì‹œê°„ ì»¬ëŸ¼ ê²°ì •
        time_column = f"scheduled_{flight_type}_local"

        if time_column not in flight_df.columns:
            return None

        flight_df[time_column] = pd.to_datetime(flight_df[time_column]).dt.floor("h")

        df_grouped = (
            flight_df.groupby([time_column, group_column]).size().unstack(fill_value=0)
        )
        df_grouped = df_grouped.sort_index()

        if df_grouped.empty:
            return None

        total_groups = df_grouped.shape[1]
        has_etc = total_groups > 9

        if has_etc:
            top_9_columns = df_grouped.sum().nlargest(9).index.tolist()
            df_grouped["etc"] = df_grouped.drop(
                columns=top_9_columns, errors="ignore"
            ).sum(axis=1)
            df_grouped = df_grouped[top_9_columns + ["etc"]]
        else:
            top_9_columns = df_grouped.columns.tolist()

        day = df_grouped.index[0].date()
        all_hours = pd.date_range(
            start=pd.Timestamp(day),
            end=pd.Timestamp(day) + pd.Timedelta(hours=23),
            freq="h",
        )
        df_grouped = df_grouped.reindex(all_hours, fill_value=0)

        group_order = df_grouped.sum().sort_values(ascending=False).index.tolist()
        if has_etc and "etc" in group_order:
            group_order.remove("etc")
            group_order.append("etc")

        default_x = df_grouped.index.strftime("%H:%M").tolist()
        traces = [
            {
                "name": column,
                "order": group_order.index(column),
                "y": df_grouped[column].tolist(),
                "acc_y": df_grouped[column].cumsum().tolist(),
            }
            for column in df_grouped.columns
        ]

        return {"traces": traces, "default_x": default_x}

    def _build_parquet_metadata(self, flight_df: pd.DataFrame) -> dict:
        """
        Parquet íŒŒì¼ì˜ ì»¬ëŸ¼ë³„ ìœ ë‹ˆí¬ê°’ ë©”íƒ€ë°ì´í„° ìƒì„±
        
        Passenger Scheduleì—ì„œ ë™ì  ì¡°ê±´ ì„¤ì •ì„ ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
        ê° ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ë“¤ì„ ì¶”ì¶œí•˜ì—¬ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë“œë¡­ë‹¤ìš´ ì˜µì…˜ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
        
        Args:
            flight_df: í•­ê³µí¸ ìŠ¤ì¼€ì¤„ DataFrame
            
        Returns:
            ì»¬ëŸ¼ë³„ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        if flight_df.empty:
            return {"columns": []}
        
        columns = []
        
        for column_name in flight_df.columns:
            try:
                # NaN ê°’ ì œê±° í›„ ìœ ë‹ˆí¬ê°’ ì¶”ì¶œ
                unique_values = flight_df[column_name].dropna().unique()
                
                # numpy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜ (JSON ì§ë ¬í™” ëŒ€ì‘)
                unique_values_list = [
                    str(value) if pd.notna(value) else None 
                    for value in unique_values
                ]
                
                # None ê°’ ì œê±° ë° ì •ë ¬
                unique_values_list = sorted([v for v in unique_values_list if v is not None])
                
                columns.append({
                    "name": column_name,
                    "unique_values": unique_values_list,
                    "count": len(unique_values_list)
                })
                
            except Exception as e:
                logger.warning(f"ì»¬ëŸ¼ '{column_name}' ë©”íƒ€ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {str(e)}")
                # ì—ëŸ¬ê°€ ë°œìƒí•œ ì»¬ëŸ¼ì€ ë¹ˆ ìœ ë‹ˆí¬ê°’ìœ¼ë¡œ ì²˜ë¦¬
                columns.append({
                    "name": column_name,
                    "unique_values": [],
                    "count": 0
                })
        
        logger.info(f"ğŸ“Š Parquet ë©”íƒ€ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(columns)}ê°œ ì»¬ëŸ¼")
        
        return {"columns": columns}
