"""
í•­ê³µí¸ ìŠ¤ì¼€ì¤„ ì²˜ë¦¬ í†µí•© ëª¨ë“ˆ (Flight Schedule Processing)

ì´ ëª¨ë“ˆì€ í•­ê³µí¸ ìŠ¤ì¼€ì¤„ ì²˜ë¦¬ì˜ Storageì™€ Response ê¸°ëŠ¥ì„ í†µí•©í•©ë‹ˆë‹¤:
- FlightScheduleStorage: Redshiftì—ì„œ í•­ê³µí¸ ë°ì´í„° ì¡°íšŒ ë° S3 ì €ì¥
- FlightScheduleResponse: í”„ë¡ íŠ¸ì—”ë“œìš© JSON ì‘ë‹µ ìƒì„± (ì°¨íŠ¸ ë°ì´í„° í¬í•¨)
"""

from datetime import datetime
from typing import Dict, List, Optional

import pandas as pd
from fastapi import HTTPException
from loguru import logger
from sqlalchemy import Connection

from packages.aws.s3.s3_manager import S3Manager
from app.routes.simulation.application.queries import (
    SELECT_AIRPORT_FLIGHTS_EXTENDED,
    SELECT_AIRPORT_SCHEDULE,
)


class FlightScheduleStorage:
    """í•­ê³µí¸ ìŠ¤ì¼€ì¤„ ë°ì´í„° ì €ì¥ ì „ë‹´ í´ë˜ìŠ¤"""

    def __init__(self):
        self.s3_manager = S3Manager()

    async def fetch_and_store(
        self,
        db: Connection,
        date: str,
        airport: str,
        flight_type: str,
        conditions: list | None,
        scenario_id: str,
        storage: str = "redshift",
    ) -> List[dict]:
        """í•­ê³µí¸ ìŠ¤ì¼€ì¤„ ë°ì´í„° ì¡°íšŒ ë° ì €ì¥"""
        try:
            # 1. ì¡°ê±´ ë³€í™˜
            converted_conditions = (
                self._convert_filter_conditions(conditions) if conditions else None
            )

            # 2. ë°ì´í„° ì¡°íšŒ
            flight_schedule_data = await self._fetch_flight_schedule_data(
                db,
                date,
                airport,
                flight_type,
                converted_conditions,
                scenario_id,
                storage,
            )

            # 3. S3 ì €ì¥
            await self._save_flight_schedule_to_s3(flight_schedule_data, scenario_id)

            return flight_schedule_data

        except Exception as e:
            logger.error(f"Flight schedule storage failed: {str(e)}")
            raise HTTPException(
                status_code=500, detail=f"Failed to process flight schedule: {str(e)}"
            )

    async def _fetch_flight_schedule_data(
        self,
        db: Connection,
        date: str,
        airport: str,
        flight_type: str,
        conditions: list | None,
        scenario_id: str,
        storage: str = "s3",
    ):
        """í•­ê³µê¸° ìŠ¤ì¼€ì¤„ ë°ì´í„° ì¡°íšŒ (S3 ìš°ì„ , Redshift ëŒ€ì²´)"""
        flight_schedule_data = None

        # S3 ë°ì´í„° í™•ì¸
        if storage == "s3":
            object_exists = await self.s3_manager.check_exists_async(
                scenario_id=scenario_id,
                filename="flight-schedule.parquet"
            )

            if object_exists:
                # S3Managerë¥¼ ì‚¬ìš©í•˜ì—¬ parquet íŒŒì¼ì„ dictë¡œ ì½ê¸°
                flight_schedule_data = await self.s3_manager.get_parquet_async(
                    scenario_id=scenario_id,
                    filename="flight-schedule.parquet",
                    as_dict=True
                )

        # Redshiftì—ì„œ ë°ì´í„° ì¡°íšŒ
        if not flight_schedule_data:
            # ë‚ ì§œì— ë”°ë¥¸ í…Œì´ë¸” ì„ íƒ
            target_date = datetime.strptime(date, "%Y-%m-%d").date()
            today = datetime.now().date()

            if target_date < today:
                # ê³¼ê±° ë°ì´í„°: flights_extended í…Œì´ë¸”
                query = SELECT_AIRPORT_FLIGHTS_EXTENDED
            else:
                # ì˜¤ëŠ˜/ë¯¸ë˜ ë°ì´í„°: schedule í…Œì´ë¸”
                query = SELECT_AIRPORT_SCHEDULE

            # redshift-connectorë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ê²½ê³  ë°©ì§€
            cursor = db.cursor()

            # flight_typeì— ë”°ë¼ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì¡°ì •
            if flight_type == "departure":
                # departure ì „ìš© ì¿¼ë¦¬ë¡œ ìˆ˜ì •
                modified_query = query.replace(
                    "AND (fe.departure_airport_iata = %s OR fe.arrival_airport_iata = %s)",
                    "AND fe.departure_airport_iata = %s",
                ).replace(
                    "AND (s.departure_station_code_iata = %s OR s.arrival_station_code_iata = %s)",
                    "AND s.departure_station_code_iata = %s",
                )
                cursor.execute(modified_query, (date, airport))
            elif flight_type == "arrival":
                # arrival ì „ìš© ì¿¼ë¦¬ë¡œ ìˆ˜ì •
                modified_query = query.replace(
                    "AND (fe.departure_airport_iata = %s OR fe.arrival_airport_iata = %s)",
                    "AND fe.arrival_airport_iata = %s",
                ).replace(
                    "AND (s.departure_station_code_iata = %s OR s.arrival_station_code_iata = %s)",
                    "AND s.arrival_station_code_iata = %s",
                )
                cursor.execute(modified_query, (date, airport))
            else:
                # ê¸°ë³¸ê°’: ê¸°ì¡´ OR ì¡°ê±´ ìœ ì§€
                cursor.execute(query, (date, airport, airport))

            columns = [desc[0] for desc in cursor.description]
            rows = cursor.fetchall()
            cursor.close()

            # DataFrameìœ¼ë¡œ ë³€í™˜
            flight_schedule_df = pd.DataFrame(rows, columns=columns)
            
            # âœ… ì¤‘ë³µ ì œê±°: ê°™ì€ ë‚ ì§œ + ê°™ì€ í•­ê³µì‚¬ + ê°™ì€ í¸ëª…ì€ ìœ ë‹ˆí¬í•˜ê²Œ ì²˜ë¦¬
            duplicate_columns = ['flight_date', 'operating_carrier_iata', 'flight_number']
            available_columns = [col for col in duplicate_columns if col in flight_schedule_df.columns]
            
            if available_columns and len(available_columns) == 3:
                before_count = len(flight_schedule_df)
                flight_schedule_df = flight_schedule_df.drop_duplicates(subset=available_columns, keep='first')
                after_count = len(flight_schedule_df)
                
                if before_count != after_count:
                    logger.info(f"ğŸ”§ ì¤‘ë³µ ì œê±°: {before_count}ê°œ â†’ {after_count}ê°œ ({before_count - after_count}ê°œ ì¤‘ë³µ ì œê±°)")
            
            flight_schedule_data = flight_schedule_df.to_dict("records")

            # ğŸš¨ ëŒ€ëŸ‰ ë°ì´í„° ë³´í˜¸: ì¡°ê±´ ì—†ìœ¼ë©´ ìµœëŒ€ 500ê°œë¡œ ì œí•œ
            if not conditions:
                if len(flight_schedule_data) > 500:
                    print(f"âš ï¸ Large dataset detected ({len(flight_schedule_data)} rows). Limiting to 500 for performance.")
                    flight_schedule_data = flight_schedule_data[:500]
            else:
                # ì¡°ê±´ í•„í„°ë§ (fieldë“¤ì€ AND, valuesëŠ” OR ì¡°ê±´)
                filtered_data = []
                for flight in flight_schedule_data:
                    include_flight = True

                    # ëª¨ë“  field ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•¨ (AND ì¡°ê±´)
                    for cond in conditions:
                        field = cond["field"]
                        values = cond["values"]
                        flight_value = flight.get(field)

                        # ğŸ”§ NULL ê°’ë„ ì˜¬ë°”ë¥´ê²Œ ë¹„êµ (None in [None] í—ˆìš©)
                        # values ì¤‘ í•˜ë‚˜ë¼ë„ ë§¤ì¹˜ë˜ë©´ ë¨ (OR ì¡°ê±´)
                        if flight_value not in values:
                            include_flight = False
                            break

                    if include_flight:
                        filtered_data.append(flight)

                flight_schedule_data = filtered_data

        return flight_schedule_data

    def _convert_filter_conditions(self, filter_conditions: list) -> list:
        """âœ… í•„í„° ì¡°ê±´ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ë§¤í•‘ ì œê±°) + unknown â†’ NULL ë³€í™˜"""
        if not filter_conditions:
            return []

        # âœ… ë§¤í•‘ ì—†ì´ ë°›ì€ ì»¬ëŸ¼ëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©
        converted = []
        for filter_cond in filter_conditions:
            field = (
                filter_cond.get("field")
                if isinstance(filter_cond, dict)
                else filter_cond.field
            )
            values = (
                filter_cond.get("values")
                if isinstance(filter_cond, dict)
                else filter_cond.values
            )

            # ğŸ†• ë²”ìš© ë¡œì§: ëª¨ë“  "unknown" ê°’ì„ NULLë¡œ ë³€í™˜
            processed_values = []
            for value in values:
                if value == "unknown":
                    processed_values.append(None)  # NULL ì¡°ê±´ìœ¼ë¡œ ë³€í™˜
                else:
                    processed_values.append(value)

            # âœ… ë³€í™˜ëœ ì¡°ê±´ ì¶”ê°€
            converted.append({"field": field, "values": processed_values})

        return converted

    async def _save_flight_schedule_to_s3(
        self, flight_schedule_data: list, scenario_id: str
    ):
        """S3ì— í•­ê³µí¸ ìŠ¤ì¼€ì¤„ ë°ì´í„° ì €ì¥"""
        if not flight_schedule_data:
            return

        # S3Managerë¥¼ ì‚¬ìš©í•˜ì—¬ parquet ì €ì¥
        await self.s3_manager.save_parquet_async(
            scenario_id=scenario_id,
            filename="flight-schedule.parquet",
            df=pd.DataFrame(flight_schedule_data)
        )


class FlightScheduleResponse:
    """í•­ê³µí¸ ìŠ¤ì¼€ì¤„ í”„ë¡ íŠ¸ì—”ë“œ ì‘ë‹µ ìƒì„± ì „ë‹´ í´ë˜ìŠ¤"""

    async def build_response(
        self,
        flight_schedule_data: list,
        applied_conditions: list | None,
        flight_type: str,
        airport: str = None,
        date: str = None,
        scenario_id: str = None,
    ) -> dict:
        """í•­ê³µí¸ ìŠ¤ì¼€ì¤„ ì‘ë‹µ ë°ì´í„° êµ¬ì„± (ì°¨íŠ¸ + ë©”íƒ€ë°ì´í„° ì „ìš©)"""
        if not flight_schedule_data:
            return self._get_empty_response(airport, date, scenario_id)

        flight_df = pd.DataFrame(flight_schedule_data)

        # ì°¨íŠ¸ ë°ì´í„° ìƒì„± (flight_typeì— ë”°ë¼ êµ¬ë¶„)
        chart_data = await self._build_chart_data(flight_df, flight_type)

        # Parquet ë©”íƒ€ë°ì´í„° ìƒì„± (Passenger Scheduleì—ì„œ ì‚¬ìš©)
        parquet_metadata = self._build_parquet_metadata(flight_df)

        # ì‘ë‹µ êµ¬ì¡°: flight-filter.jsonì²˜ëŸ¼ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ë¨¼ì € í¬í•¨
        response = {}
        
        # ìš”ì²­ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (ì²˜ìŒ 3ê°œ í‚¤)
        if airport:
            response["airport"] = airport
        if date:
            response["date"] = date
        if scenario_id:
            response["scenario_id"] = scenario_id
            
        # ê¸°ì¡´ ì‘ë‹µ ë°ì´í„°
        response.update({
            "total": len(flight_df),
            "chart_x_data": chart_data.get("x_data", []),
            "chart_y_data": chart_data.get("y_data", {}),
            "parquet_metadata": parquet_metadata,
        })

        return response

    def _get_empty_response(self, airport: str = None, date: str = None, scenario_id: str = None) -> dict:
        """ë¹ˆ ì‘ë‹µ ë°ì´í„° ë°˜í™˜ (ì°¨íŠ¸ + ë©”íƒ€ë°ì´í„° ì „ìš©)"""
        response = {}
        
        # ìš”ì²­ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ (ì²˜ìŒ 3ê°œ í‚¤)
        if airport:
            response["airport"] = airport
        if date:
            response["date"] = date
        if scenario_id:
            response["scenario_id"] = scenario_id
            
        # ê¸°ë³¸ ì‘ë‹µ ë°ì´í„°
        response.update({
            "total": 0,
            "chart_x_data": [],
            "chart_y_data": {},
            "parquet_metadata": [],
        })
        
        return response

    async def _build_chart_data(
        self, flight_df: pd.DataFrame, flight_type: str = "departure"
    ) -> dict:
        """ì°¨íŠ¸ ë°ì´í„° ìƒì„± - departure/arrival êµ¬ë¶„"""
        chart_result = {}
        chart_x_data = []

        # flight_typeì— ë”°ë¼ ì‚¬ìš©í•  í„°ë¯¸ë„ ì»¬ëŸ¼ ê²°ì •
        terminal_column = f"{flight_type}_terminal"

        # flight_typeì— ë”°ë¼ country/region ì»¬ëŸ¼ ê²°ì •
        if flight_type == "departure":
            country_column = "arrival_country"  # êµ­ê°€ ì´ë¦„ ì‚¬ìš©
            region_column = "arrival_region"
        else:  # arrival
            country_column = "departure_country"  # êµ­ê°€ ì´ë¦„ ì‚¬ìš©
            region_column = "departure_region"

        # ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•œ ê·¸ë£¹ ì»¬ëŸ¼ë“¤
        group_columns = [
            "operating_carrier_name",
            terminal_column,
            "flight_type",
            country_column,
            region_column,
        ]
        group_labels = ["airline", "terminal", "type", "country", "region"]

        for i, group_column in enumerate(group_columns):
            if group_column in flight_df.columns:
                chart_result_data = await self._create_flight_schedule_chart(
                    flight_df, group_column, flight_type
                )

                if chart_result_data:
                    chart_result[group_labels[i]] = chart_result_data["traces"]
                    chart_x_data = chart_result_data["default_x"]

        return {
            "x_data": chart_x_data,
            "y_data": chart_result,
        }

    async def _create_flight_schedule_chart(
        self, flight_df: pd.DataFrame, group_column: str, flight_type: str = "departure"
    ):
        """í•­ê³µí¸ ìŠ¤ì¼€ì¤„ ì°¨íŠ¸ ë°ì´í„° ìƒì„±"""
        # flight_typeì— ë”°ë¼ ì‚¬ìš©í•  ì‹œê°„ ì»¬ëŸ¼ ê²°ì •
        time_column = f"scheduled_{flight_type}_local"

        if time_column not in flight_df.columns:
            return None

        # null ê°’ì„ "Unknown"ìœ¼ë¡œ ë³€í™˜ (ëª¨ë“  ê·¸ë£¹ ì»¬ëŸ¼ì— ëŒ€í•´)
        flight_df = flight_df.copy()
        flight_df[group_column] = flight_df[group_column].fillna("Unknown")

        flight_df[time_column] = pd.to_datetime(flight_df[time_column]).dt.floor("h")

        df_grouped = (
            flight_df.groupby([time_column, group_column]).size().unstack(fill_value=0)
        )
        df_grouped = df_grouped.sort_index()

        if df_grouped.empty:
            return None

        total_groups = df_grouped.shape[1]
        has_etc = total_groups > 9

        if has_etc:
            top_9_columns = df_grouped.sum().nlargest(9).index.tolist()
            df_grouped["ETC"] = df_grouped.drop(
                columns=top_9_columns, errors="ignore"
            ).sum(axis=1)
            df_grouped = df_grouped[top_9_columns + ["ETC"]]
        else:
            top_9_columns = df_grouped.columns.tolist()

        day = df_grouped.index[0].date()
        all_hours = pd.date_range(
            start=pd.Timestamp(day),
            end=pd.Timestamp(day) + pd.Timedelta(hours=23),
            freq="h",
        )
        df_grouped = df_grouped.reindex(all_hours, fill_value=0)

        group_order = df_grouped.sum().sort_values(ascending=False).index.tolist()
        if has_etc and "ETC" in group_order:
            group_order.remove("ETC")
            group_order.append("ETC")

        default_x = df_grouped.index.strftime("%H:%M").tolist()
        traces = [
            {
                "name": column,
                "order": group_order.index(column),
                "y": df_grouped[column].tolist(),
                "acc_y": df_grouped[column].cumsum().tolist(),
            }
            for column in df_grouped.columns
        ]

        return {"traces": traces, "default_x": default_x}

    def _build_parquet_metadata(self, flight_df: pd.DataFrame) -> list:
        """
        ìƒˆë¡œìš´ Parquet ë©”íƒ€ë°ì´í„° ìƒì„± - flights + indices í¬í•¨
        
        ê° ì»¬ëŸ¼ì˜ ìœ ë‹ˆí¬ê°’ë³„ë¡œ í•´ë‹¹í•˜ëŠ” í•­ê³µí¸ ì¡°í•©ê³¼ ì¸ë±ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
        í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í•„í„° ì„ íƒ ì‹œ êµ¬ì²´ì ì¸ í•­ê³µí¸ë“¤ì„ ë°”ë¡œ í™•ì¸í•  ìˆ˜ ìˆê³ ,
        ë°±ì—”ë“œì—ì„œëŠ” ì¸ë±ìŠ¤ë¥¼ í†µí•´ ë¹ ë¥¸ ë°ì´í„° ì¡°íšŒê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        
        Args:
            flight_df: í•­ê³µí¸ ìŠ¤ì¼€ì¤„ DataFrame
            
        Returns:
            ì»¬ëŸ¼ë³„ ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸ [{"column": "ì»¬ëŸ¼ëª…", "values": {"ê°’": {"flights": [...], "indices": [...]}}}]
        """
        if flight_df.empty:
            return []
        
        # í•µì‹¬ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        required_cols = ['operating_carrier_iata', 'flight_number']
        if not all(col in flight_df.columns for col in required_cols):
            logger.error("í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë¨: operating_carrier_iata, flight_number")
            return []
        
        metadata = []
        
        # ì„ íƒëœ ì»¬ëŸ¼ë“¤ë§Œ ì²˜ë¦¬ (departure ì»¬ëŸ¼ì€ arrival ìŒë„ í¬í•¨)
        target_columns = [
            'operating_carrier_name',
            'departure_airport_iata', 'arrival_airport_iata',
            'scheduled_departure_local', 'scheduled_arrival_local',
            'aircraft_type_icao',
            'departure_terminal', 'arrival_terminal',
            'flight_type',
            'departure_city', 'arrival_city',
            'departure_country', 'arrival_country',
            'departure_region', 'arrival_region',
            'total_seats'
        ]
        
        for column_name in target_columns:
            if column_name not in flight_df.columns:
                continue
                
            try:
                # 1. NaN ì œê±° í›„ ìœ ë‹ˆí¬ê°’ ì¶”ì¶œ
                unique_values = flight_df[column_name].dropna().unique()
                
                # 2. ê° ìœ ë‹ˆí¬ê°’ì— ëŒ€í•œ ë°ì´í„° êµ¬ì„±
                values_dict = {}
                
                for unique_value in unique_values:
                    # í•´ë‹¹ ê°’ì— ë§¤ì¹˜ë˜ëŠ” í–‰ë“¤ ì°¾ê¸°
                    mask = flight_df[column_name] == unique_value
                    matched_rows = flight_df[mask]
                    
                    # flights ì¡°í•© ìƒì„± (operating_carrier_iata + flight_number)
                    flights = []
                    for _, row in matched_rows.iterrows():
                        carrier = str(row['operating_carrier_iata']) if pd.notna(row['operating_carrier_iata']) else ""
                        flight_num = str(row['flight_number']) if pd.notna(row['flight_number']) else ""
                        if carrier and flight_num:  # ë‘˜ ë‹¤ ìœ íš¨í•œ ê°’ì¼ ë•Œë§Œ ì¶”ê°€
                            flights.append(f"{carrier}{flight_num}")
                    
                    # ì¸ë±ìŠ¤ ì¶”ì¶œ (ì›ë³¸ DataFrame ê¸°ì¤€)
                    indices = matched_rows.index.tolist()
                    
                    # ê²°ê³¼ ì €ì¥ (ìœ íš¨í•œ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ)
                    if flights and indices:
                        values_dict[str(unique_value)] = {
                            "flights": flights,
                            "indices": indices
                        }
                
                # ì»¬ëŸ¼ ë©”íƒ€ë°ì´í„° ì¶”ê°€ (ê°’ì´ ìˆì„ ë•Œë§Œ)
                if values_dict:
                    metadata.append({
                        "column": column_name,
                        "values": values_dict
                    })
                
            except Exception as e:
                logger.warning(f"ì»¬ëŸ¼ '{column_name}' ë©”íƒ€ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {str(e)}")
                continue
        
        logger.info(f"ğŸ“Š ìƒˆë¡œìš´ Parquet ë©”íƒ€ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(metadata)}ê°œ ì»¬ëŸ¼")
        return metadata
