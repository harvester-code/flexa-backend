from typing import Optional

import pandas as pd
from loguru import logger

from app.routes.home.domain.repository import IHomeRepository
from packages.aws.s3.s3_manager import S3Manager


class HomeRepository(IHomeRepository):
    def __init__(self, s3_manager: S3Manager):
        self.s3_manager = s3_manager

    async def load_simulation_parquet(self, scenario_id: str) -> Optional[pd.DataFrame]:
        return await self.s3_manager.get_parquet_async(
            scenario_id, "simulation-pax.parquet"
        )

    async def load_metadata(self, scenario_id: str, filename: str) -> Optional[dict]:
        return await self.s3_manager.get_json_async(scenario_id=scenario_id, filename=filename)

    async def is_cache_valid(self, scenario_id: str, cache_filename: str) -> bool:
        """ìºì‹œê°€ ìœ íš¨í•œì§€ í™•ì¸ (simulation-pax.parquet ìˆ˜ì •ì¼ê³¼ ë¹„êµ)
        
        ìºì‹œê°€ parquet íŒŒì¼ë³´ë‹¤ ìµœì‹ ì´ë©´ ìœ íš¨, ì˜¤ë˜ë˜ì—ˆìœ¼ë©´ ë¬´íš¨
        """
        # 1. ìºì‹œ íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        cache_metadata = await self.s3_manager.get_metadata_async(scenario_id, cache_filename)
        if not cache_metadata:
            logger.debug(f"Cache file not found: {cache_filename}")
            return False
        
        # 2. parquet íŒŒì¼ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
        parquet_metadata = await self.s3_manager.get_metadata_async(scenario_id, "simulation-pax.parquet")
        if not parquet_metadata:
            logger.warning(f"Parquet file not found for scenario_id={scenario_id}")
            return False
        
        cache_modified = cache_metadata.get('last_modified')
        parquet_modified = parquet_metadata.get('last_modified')
        
        if not cache_modified or not parquet_modified:
            logger.warning(f"Missing modification timestamps for scenario_id={scenario_id}")
            return False
        
        # 3. íƒ€ì„ìŠ¤íƒ¬í”„ ë¹„êµ: ìºì‹œê°€ parquetë³´ë‹¤ ìµœì‹ ì´ë©´ ìœ íš¨
        is_valid = cache_modified > parquet_modified
        
        if is_valid:
            logger.info(f"âœ… Cache valid for {scenario_id}: cache={cache_modified}, parquet={parquet_modified}")
        else:
            logger.info(f"ğŸ”„ Cache outdated for {scenario_id}: cache={cache_modified}, parquet={parquet_modified}")
        
        return is_valid

    async def load_cached_response(self, scenario_id: str, cache_filename: str) -> Optional[dict]:
        """ìºì‹œëœ ì‘ë‹µ ë¡œë“œ"""
        cached_data = await self.s3_manager.get_json_async(scenario_id, cache_filename)
        if cached_data:
            logger.info(f"ğŸ“¦ Loaded cached response for {scenario_id}")
        return cached_data

    async def save_cached_response(self, scenario_id: str, cache_filename: str, data: dict) -> bool:
        """ê³„ì‚°ëœ ì‘ë‹µì„ ìºì‹œì— ì €ì¥"""
        success = await self.s3_manager.save_json_async(scenario_id, cache_filename, data)
        if success:
            logger.info(f"ğŸ’¾ Saved cache for {scenario_id}: {cache_filename}")
        else:
            logger.error(f"âŒ Failed to save cache for {scenario_id}")
        return success
